{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72400,
     "status": "ok",
     "timestamp": 1564545488472,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "jUEE3LJ45J0h",
    "outputId": "d035b0a9-c5a5-401a-e508-7ba0e5902404"
   },
   "outputs": [],
   "source": [
    "#Block 1 server setup \n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okDrJp5-5YJG"
   },
   "outputs": [],
   "source": [
    "#Block 2 sync colabserver with drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q cairocffi editdistance \n",
    "!sudo apt install -q libcairo2-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9273,
     "status": "ok",
     "timestamp": 1564545529204,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "0tA5-0dD5q48",
    "outputId": "36a4a269-d3af-4732-e5e5-3092f0643910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\r\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\r\n"
     ]
    }
   ],
   "source": [
    "!apt install -q graphviz\n",
    "!pip install -q pydot\n",
    "!pip install -q matplotlib graphviz pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "import sys\n",
    "#sys.path.append(\"./anaconda3/envs/workshop/lib/python3.7/site-packages\")\n",
    "sys.path.append(\"/home/mahim/anaconda3/envs/workshop/lib/python3.7/site-packages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhO3Djbm5ua4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mahim/Desktop/Bangal_OCR-using_CRNN-with-CTC-loss', '/home/mahim/anaconda3/envs/workshop/lib/python37.zip', '/home/mahim/anaconda3/envs/workshop/lib/python3.7', '/home/mahim/anaconda3/envs/workshop/lib/python3.7/lib-dynload', '', '/home/mahim/anaconda3/envs/workshop/lib/python3.7/site-packages', '/home/mahim/anaconda3/envs/workshop/lib/python3.7/site-packages/IPython/extensions', '/home/mahim/.ipython']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed8e898a5af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#import editdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "print(sys.path)\n",
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL.ImageOps \n",
    "\n",
    "\n",
    "# import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1564563921982,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "td9frBqM6EsX",
    "outputId": "5713f5f9-29c2-48d0-ce4b-15b32e492e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz \n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = 'image_ocr'\n",
    "\n",
    "# character classes and matching regex filter\n",
    "regex = r'^[a-z ]+$'\n",
    "alphabet = u'abcdefghijklmnopqrstuvwxyz '\n",
    "print(alphabet)\n",
    "np.random.seed(55)\n",
    "\n",
    "BASE = 'data gen/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1912,
     "status": "ok",
     "timestamp": 1564563924605,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "nBs_uiUl6JCl",
    "outputId": "eabb2ada-d333-462d-d657-0ddc08d3740b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef text_to_labels(text):\\n    ret = []\\n    for char in text:\\n        ret.append(alphabet.find(char))\\n    return ret\\n\\n\\n# Reverse translation of numerical classes back to characters\\ndef labels_to_text(labels):\\n    ret = []\\n    for c in labels:\\n        if c == len(alphabet):  # CTC Blank\\n            ret.append(\"\")\\n        else:\\n            ret.append(alphabet[c])\\n    return \"\".join(ret)\\n\\n\\n# only a-z and space..probably not to difficult\\n# to expand to uppercase and symbols\\n\\ndef is_valid_str(in_str):\\n    search = re.compile(regex, re.UNICODE).search\\n    return bool(search(in_str))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# this creates larger \"blotches\" of noise which look\n",
    "# more realistic than just adding gaussian noise\n",
    "# assumes greyscale with pixels ranging from 0 to 1\n",
    "def speckle(img):\n",
    "    severity = np.random.uniform(0, 0.6)\n",
    "    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n",
    "    img_speck = (img + blur)\n",
    "    img_speck[img_speck > 1] = 1\n",
    "    img_speck[img_speck <= 0] = 0\n",
    "    return img_speck\n",
    "\n",
    "\n",
    "# paints the string in a random location the bounding box\n",
    "# also uses a random font, a slight random rotation,\n",
    "# and a random amount of speckle noise\n",
    "\n",
    "\n",
    "#if you just change the paint function with the propper inputs everything else should work just fine  \n",
    "'''\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n",
    "    with cairo.Context(surface) as context:\n",
    "        context.set_source_rgb(1, 1, 1)  # White\n",
    "        context.paint()\n",
    "        # this font list works in CentOS 7\n",
    "        if multi_fonts:\n",
    "            fonts = ['Century Schoolbook', 'Courier', 'STIX', 'URW Chancery L', 'FreeMono']\n",
    "            context.select_font_face(np.random.choice(fonts), cairo.FONT_SLANT_NORMAL,\n",
    "                                     np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n",
    "        else:\n",
    "            context.select_font_face('Courier', cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n",
    "        context.set_font_size(25)\n",
    "        box = context.text_extents(text)\n",
    "        border_w_h = (4, 4)\n",
    "        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n",
    "            raise IOError('Could not fit string into image. Max char count is too large for given image width.')\n",
    "\n",
    "        # teach the RNN translational invariance by\n",
    "        # fitting text box randomly on canvas, with some room to rotate\n",
    "        max_shift_x = w - box[2] - border_w_h[0]\n",
    "        max_shift_y = h - box[3] - border_w_h[1]\n",
    "        top_left_x = np.random.randint(0, int(max_shift_x))\n",
    "        if ud:\n",
    "            top_left_y = np.random.randint(0, int(max_shift_y))\n",
    "        else:\n",
    "            top_left_y = h // 2\n",
    "        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n",
    "        context.set_source_rgb(0, 0, 0)\n",
    "        context.show_text(text)\n",
    "\n",
    "    buf = surface.get_data()\n",
    "    a = np.frombuffer(buf, np.uint8)\n",
    "    a.shape = (h, w, 4)\n",
    "    a = a[:, :, 0]  # grab single channel\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
    "    a = speckle(a)\n",
    "\n",
    "    return a\n",
    "'''\n",
    "fonts = ImageFont.truetype(BASE+'SutonnyOMJ.ttf',20, layout_engine=ImageFont.LAYOUT_RAQM)\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    im = Image.new(\"RGB\",(w,h))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.text((10, 10), text, font=fonts)\n",
    "    inverted_image = PIL.ImageOps.invert(im)\n",
    "    inverted_image = inverted_image.convert('RGB') \n",
    "    open_cv_image = np.array(inverted_image) \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    a = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    #print(a.shape)# has to be (64, 128)\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - np.random.randint(0, 10)) / w + 1)\n",
    "    a = speckle(a)\n",
    "    return a\n",
    "\n",
    "h = 64\n",
    "w = 128\n",
    "a = paint_text('ন্দ্যুচ্যেদ্র্যুল্বাপ্র্যী',h = h, w = w)\n",
    "print(a.shape)\n",
    "b = a.reshape((h, w))\n",
    "#print(b.shape)\n",
    "plt.imshow(b, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n",
    "    ret = []\n",
    "    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n",
    "    len_val = len(matrix_list[0])\n",
    "    if stop_ind is None:\n",
    "        stop_ind = len_val\n",
    "    assert stop_ind <= len_val\n",
    "\n",
    "    a = list(range(stop_ind))\n",
    "    np.random.shuffle(a)\n",
    "    a += list(range(stop_ind, len_val))\n",
    "    for mat in matrix_list:\n",
    "        if isinstance(mat, np.ndarray):\n",
    "            ret.append(mat[a])\n",
    "        elif isinstance(mat, list):\n",
    "            ret.append([mat[i] for i in a])\n",
    "        else:\n",
    "            raise TypeError('`shuffle_mats_or_lists` only supports '\n",
    "                            'numpy.array and list objects.')\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Translation of characters to unique integer values\n",
    "#need to change here for bangla encoding\n",
    "def load_obj(name):\n",
    "    with open(BASE+name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "BCC_map = load_obj(\"BCC_map\")\n",
    "rBCC_map = load_obj(\"rBCC_map\")\n",
    "\n",
    "print(len(BCC_map.keys()))\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    #print(\"labels_to_text\")\n",
    "    for c in labels:\n",
    "        if c == len(BCC_map.keys()):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(BCC_map[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "def text_to_labels(text):\n",
    "    #print(\"dcd\")\n",
    "    i = 0\n",
    "    j = 0\n",
    "    far = 9\n",
    "    out  = []\n",
    "    while(i<len(text)):\n",
    "        #print(i)\n",
    "        j = min(i+far, len(text))\n",
    "        found = True\n",
    "        while(text[i:j] not in rBCC_map):\n",
    "            #print('j = ', j)\n",
    "            #print(text[i:j])\n",
    "            #print(i, \" \", j)\n",
    "            j-=1\n",
    "            if(j == i):\n",
    "                i = i+1\n",
    "                #print('comes inside, i = ', str(i))\n",
    "                found = False\n",
    "                break\n",
    "        if found:\n",
    "            out.append(rBCC_map[text[i:j]])\n",
    "            i = j\n",
    "        #print(out)  \n",
    "    return out\n",
    "#print(actual)\n",
    "  \n",
    "  \n",
    "'''\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Reverse translation of numerical classes back to characters\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "# only a-z and space..probably not to difficult\n",
    "# to expand to uppercase and symbols\n",
    "\n",
    "def is_valid_str(in_str):\n",
    "    search = re.compile(regex, re.UNICODE).search\n",
    "    return bool(search(in_str))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2SlI26H6Tsx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Uses generator functions to supply train/test with\n",
    "# data. Image renderings are text are created on the fly\n",
    "# each time with random perturbations\n",
    "\n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, monogram_file, bigram_file, minibatch_size,\n",
    "                 img_w, img_h, downsample_factor, val_split,\n",
    "                 absolute_max_string_len=100):\n",
    "\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.monogram_file = monogram_file\n",
    "        self.bigram_file = bigram_file\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.val_split = val_split\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return len(BCC_map.keys()) + 1\n",
    "\n",
    "    # num_words can be independent of the epoch size due to the use of generators\n",
    "    # as max_string_len grows, num_words can grow\n",
    "    def build_word_list(self, num_words, max_string_len=None, mono_fraction=0.5):\n",
    "        assert max_string_len <= self.absolute_max_string_len\n",
    "        assert num_words % self.minibatch_size == 0\n",
    "        #assert (self.val_split * num_words) % self.minibatch_size == 0\n",
    "        print(\"build_word_list\")\n",
    "        self.num_words = num_words\n",
    "        self.string_list = [''] * self.num_words\n",
    "        tmp_string_list = []\n",
    "        self.max_string_len = max_string_len\n",
    "        self.Y_data = np.ones([self.num_words, self.absolute_max_string_len]) * -1\n",
    "        self.X_text = []\n",
    "        self.Y_len = [0] * self.num_words\n",
    "        print(\"build_word_list monogram started\")\n",
    "        # monogram file is sorted by frequency in english speech\n",
    "        with codecs.open(self.monogram_file, mode='r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                #print(\"len(tmp_string_list) = \" + str(len(tmp_string_list)), \" int(self.num_words * mono_fraction) = \" + str(int(self.num_words * mono_fraction)) )\n",
    "                #print('mono fraction = ', str(mono_fraction) + \" line \" + str(line))\n",
    "                if len(tmp_string_list) == int(self.num_words * mono_fraction):\n",
    "                    break\n",
    "                word = line.rstrip()\n",
    "                #print(len(text_to_labels(word)), \" \",max_string_len)\n",
    "                \n",
    "                if max_string_len == -1 or max_string_len is None or len(text_to_labels(word)) <= max_string_len:\n",
    "                    tmp_string_list.append(word)\n",
    "                    #print(word)\n",
    "                    #print(\"comes inside \")\n",
    "                #print(\"for one line loop ends\")\n",
    "\n",
    "        # bigram file contains common word pairings in english speech\n",
    "        print(\"build_word_list after monogram end and bigram start\")\n",
    "        with codecs.open(self.bigram_file, mode='r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if len(tmp_string_list) == self.num_words:\n",
    "                    break\n",
    "                columns = line.lower().split()\n",
    "                word = columns[0] + ' ' + columns[1]\n",
    "                if (max_string_len == -1 or max_string_len is None or len(text_to_labels(word)) <= max_string_len):\n",
    "                    tmp_string_list.append(word)\n",
    "        if len(tmp_string_list) != self.num_words:\n",
    "            raise IOError('Could not pull enough words from supplied monogram and bigram files. ' + \"len(tmp_string_list) = \" + str(len(tmp_string_list)) + \" self.num_words\"+ str( self.num_words))\n",
    "        # interlace to mix up the easy and hard words\n",
    "        self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n",
    "        self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n",
    "        print(\"build_word_list after bi gram ending\")\n",
    "        for i, word in enumerate(self.string_list):\n",
    "            #print(self.Y_data[i, 0:len(word)])\n",
    "            #print(text_to_labels(word))\n",
    "            \n",
    "            self.Y_len[i] = len(text_to_labels(word))\n",
    "            self.Y_data[i, 0:len(text_to_labels(word))] = text_to_labels(word)\n",
    "            \n",
    "            \n",
    "            self.X_text.append(word)\n",
    "        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n",
    "\n",
    "        self.cur_val_index = self.val_split\n",
    "        self.cur_train_index = 0\n",
    "\n",
    "    # each time an image is requested from train/val/test, a new random\n",
    "    # painting of the text is performed\n",
    "    def get_batch(self, index, size, train):\n",
    "        #print(\"get_batch\")\n",
    "        # width and height are backwards from typical Keras convention\n",
    "        # because width is the time dimension when it gets fed into the RNN\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            X_data = np.ones([size, 1, self.img_w, self.img_h])\n",
    "        else:\n",
    "            X_data = np.ones([size, self.img_w, self.img_h, 1])\n",
    "\n",
    "        labels = np.ones([size, self.absolute_max_string_len])\n",
    "        input_length = np.zeros([size, 1])\n",
    "        label_length = np.zeros([size, 1])\n",
    "        source_str = []\n",
    "        for i in range(size):\n",
    "            # Mix in some blank inputs.  This seems to be important for\n",
    "            # achieving translational invariance\n",
    "            if train and i > size - 4:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n",
    "                labels[i, 0] = self.blank_label\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = 1\n",
    "                source_str.append('')\n",
    "            else:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n",
    "                labels[i, :] = self.Y_data[index + i]\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = self.Y_len[index + i]\n",
    "                source_str.append(self.X_text[index + i])\n",
    "        inputs = {'the_input': X_data,\n",
    "                  'the_labels': labels,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': source_str  # used for visualization only\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([size])}  # dummy data for dummy loss function\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def next_train(self):\n",
    "        print(\"next_train\")\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_train_index, self.minibatch_size, train=True)\n",
    "            self.cur_train_index += self.minibatch_size\n",
    "            #print(self.cur_train_index)\n",
    "            if self.cur_train_index >= self.val_split:\n",
    "                self.cur_train_index = self.cur_train_index % 32\n",
    "                (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists(\n",
    "                    [self.X_text, self.Y_data, self.Y_len], self.val_split)\n",
    "            yield ret\n",
    "\n",
    "    def next_val(self):\n",
    "        print(\"next_val\")\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_val_index, self.minibatch_size, train=False)\n",
    "            self.cur_val_index += self.minibatch_size\n",
    "            if self.cur_val_index >= self.num_words:\n",
    "                self.cur_val_index = self.val_split + self.cur_val_index % 32\n",
    "            yield ret\n",
    "#https://github.com/keras-team/keras/blob/master/keras/callbacks.py\n",
    "#these are built in functions in callbacks \n",
    "    def on_train_begin(self, logs={}):\n",
    "        print(\"on_train_begin called in TextImageGenerator\")\n",
    "        self.build_word_list(16000, 30, 1)\n",
    "        self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                  rotate=False, ud=False, multi_fonts=False)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"on_epoch_begin called in TextImageGenerator\")\n",
    "        # rebind the paint function to implement curriculum learning\n",
    "        if 3 <= epoch < 6:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=False, ud=True, multi_fonts=False)\n",
    "        elif 6 <= epoch < 9:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=False, ud=True, multi_fonts=True)\n",
    "        elif epoch >= 9:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=True, ud=True, multi_fonts=True)\n",
    "        if epoch >= 21: #and self.max_string_len < 12:\n",
    "            self.build_word_list(32000, 70, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ivXO1p66WtD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# the actual loss calc occurs here despite it not being\n",
    "# an internal Keras loss function\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JtUG4bD6ZuZ"
   },
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(BASE+'models', 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input.T, cmap='Greys_r')\n",
    "            plt.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IusZ_cAx6gnM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(run_name, start_epoch, stop_epoch, img_w):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "    minibatch_size = 32\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "    '''\n",
    "    img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                 bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                 minibatch_size=minibatch_size,\n",
    "                                 img_w=img_w,\n",
    "                                 img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 2),\n",
    "                                 val_split=words_per_epoch - val_words\n",
    "                                 )\n",
    "'''\n",
    "    fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "    img_gen = TextImageGenerator(monogram_file= BASE+'mono.txt',\n",
    "                                 bigram_file=BASE+'bi.txt',\n",
    "                                 minibatch_size=minibatch_size,\n",
    "                                 img_w=img_w,\n",
    "                                 img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 2),\n",
    "                                 val_split=words_per_epoch - val_words\n",
    "                                 )\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    #conv_to_rnn_dims = (img_w , (img_h * conv_filters))\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirectional GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(BASE+'models/', 'weights%02d.h5' % (start_epoch - 1))\n",
    "        model.load_weights(weight_file)\n",
    "    #captures output of softmax so we can decode the output during visualization\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    "    \n",
    "    model.fit_generator(generator=img_gen.next_train(),\n",
    "                        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n",
    "                        epochs=stop_epoch,\n",
    "                        validation_data=img_gen.next_val(),\n",
    "                        validation_steps=val_words // minibatch_size,\n",
    "                        callbacks=[viz_cb, img_gen],\n",
    "                        initial_epoch=start_epoch)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21718,
     "status": "error",
     "timestamp": 1564568902762,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "kwX0XUvn6rat",
    "outputId": "e8cbf03d-8930-45a7-9d7a-0bc65f4dd209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 66)       67650       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 66)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,901,394\n",
      "Trainable params: 4,901,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "on_train_begin called in TextImageGenerator\n",
      "build_word_list\n",
      "build_word_list monogram started\n",
      "build_word_list after monogram end and bigram start\n",
      "build_word_list after bi gram ending\n",
      "Epoch 1/20\n",
      "on_epoch_begin called in TextImageGenerator\n",
      "next_val\n",
      "next_train\n",
      "303/400 [=====================>........] - ETA: 1:52 - loss: 64.9751"
     ]
    }
   ],
   "source": [
    "run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "train(run_name, 0, 20, 128)\n",
    "# increase to wider images and start at epoch 20. The learned weights are reloaded\n",
    "#train(run_name, 20, 25, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9191,
     "status": "ok",
     "timestamp": 1564545571630,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "cFoYcBVy6zga",
    "outputId": "78a32312-50cd-4d91-902c-e9358a0093d3"
   },
   "outputs": [],
   "source": [
    "|!wget https://github.com/Tony607/keras-image-ocr/releases/download/V0.1/weights24.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9063,
     "status": "ok",
     "timestamp": 1564545606093,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "AigNGQQET1ic",
    "outputId": "96198262-f89b-4c61-ae40-6bc3821d89d1"
   },
   "outputs": [],
   "source": [
    "weight_file = BASE+\"models\"+'/weights21.h5'\n",
    "img_w = 128\n",
    "# Input Parameters\n",
    "img_h = 64\n",
    "words_per_epoch = 16000\n",
    "val_split = 0.2\n",
    "val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 100\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, 1)\n",
    "\n",
    "fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                             bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                             minibatch_size=minibatch_size,\n",
    "                             img_w=img_w,\n",
    "                             img_h=img_h,\n",
    "                             downsample_factor=(pool_size ** 2),\n",
    "                             val_split=words_per_epoch - val_words\n",
    "                             )\n",
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "# Keras doesn't currently support loss funcs with extra parameters\n",
    "# so CTC loss is implemented in a lambda layer\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# clipnorm seems to speeds up convergence\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "model.load_weights(weight_file)\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "test_func = K.function([input_data], [y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3926,
     "status": "ok",
     "timestamp": 1564545615700,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "zI-inKsqT3aP",
    "outputId": "601b6b96-d4b9-4b8f-a9dd-9e5617f9bbd6"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "414WVPKMT7s2"
   },
   "outputs": [],
   "source": [
    "model_p = Model(inputs=input_data, outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6s1vJm-T-03"
   },
   "outputs": [],
   "source": [
    "def decode_predict_ctc(out, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "        beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "        lables = K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n",
    "                           greedy=False, beam_width=beam_width, top_paths=top_paths)[0][i])[0]\n",
    "        text = labels_to_text(lables)\n",
    "        print(text)\n",
    "        results.append(text)\n",
    "    return results\n",
    "  \n",
    "def predit_a_image(a, top_paths = 1):\n",
    "    c = np.expand_dims(a.T, axis=0)\n",
    "    net_out_value = model_p.predict(c)\n",
    "    top_pred_texts = decode_predict_ctc(net_out_value, top_paths)\n",
    "    return top_pred_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4200,
     "status": "ok",
     "timestamp": 1564546026456,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "VrduBBbrMG5P",
    "outputId": "fdfb4362-05d2-49c6-83c9-d69c7e7597d5"
   },
   "outputs": [],
   "source": [
    "ls drive/Bangla_OCR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1393,
     "status": "ok",
     "timestamp": 1564545651998,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "RYR1241AUBUI",
    "outputId": "ea63fcc4-056a-452f-a2c0-65502b1413f3"
   },
   "outputs": [],
   "source": [
    "h = 64\n",
    "w = 128\n",
    "a = paint_text('অংশগ্রহণকারিণী',h = h, w = w)\n",
    "print(a.shape)\n",
    "b = a.reshape((h, w))\n",
    "#print(b.shape)\n",
    "plt.imshow(b, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "c = np.expand_dims(a.T, axis=0)\n",
    "print(c.shape)\n",
    "net_out_value = model_p.predict(c)\n",
    "#print(net_out_value.shape)\n",
    "pred_texts = decode_predict_ctc(net_out_value)\n",
    "pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1564547143394,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "7UrDK-zEUDhF",
    "outputId": "c612ae51-a3c1-4ac6-b9a9-cc4d19cba8e4"
   },
   "outputs": [],
   "source": [
    "predit_a_image(a, top_paths = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1564477789440,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "8x5NdoWgUiDC",
    "outputId": "ca3c6dc3-a0ae-4caf-c5c9-1c7c2fb444a0"
   },
   "outputs": [],
   "source": [
    "plt.imshow(net_out_value[0].T, cmap='binary', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1564547484363,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "d98pv6FhUtna",
    "outputId": "c437a1c3-44cd-4af5-d5a8-1c65e263f6e2"
   },
   "outputs": [],
   "source": [
    "#if you just change the paint function with the propper inputs everything else should work just fine  \n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL.ImageOps \n",
    "\n",
    "fonts = ImageFont.truetype(BASE+'SutonnyOMJ.ttf',20, layout_engine=ImageFont.LAYOUT_RAQM)\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    #print(text)\n",
    "    im = Image.new(\"RGB\",(w,h))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.text((10, 10), text, font=fonts)\n",
    "    #im.show()\n",
    "    inverted_image = PIL.ImageOps.invert(im)\n",
    "    inverted_image = inverted_image.convert('RGB') \n",
    "    open_cv_image = np.array(inverted_image) \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    a = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    plt.imshow(a)\n",
    "    plt.show()\n",
    "    print(a.shape)# has to be (64, 128)\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
    "    a = speckle(a)\n",
    "    return a\n",
    "img = paint_text(\"দৃষ্টিভঙ্গি\", 128, 64)\n",
    "print(img.shape)\n",
    "print(img.shape)\n",
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1564482054605,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "nlpZeWNIXAXA",
    "outputId": "c75f32c9-9576-46ae-c2f2-b19753b2b7c6"
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "#img = np.array(img) \n",
    "# Convert RGB to BGR \n",
    "#img = img[:, :, ::-1].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1564482064086,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "EcBG4zC9XSXh",
    "outputId": "b9b30756-fa76-4129-9328-8a2fc89b296f"
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "#img = np.rollaxis(img, 1, 0)\n",
    "#img = np.rollaxis(img, 2, 1)\n",
    "print(img.shape)\n",
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gaV-4vT-Xm1K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BANGLA_OCR.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
